---
title: 全文检索服务方案
cover: false
date: 2024-01-09 09:36:24
tags:
categories:
 - [软件工程,全文检索]
top:
coverImg:
---

# 1. 摘要 

全球性的信息社会正在逐步形成，推进政府部门政务工作的自动化、网络化以及电子化己是大势所趋。政务信息资源的开发利用作为电子政务建设的重要内容结合重点政务工作，推动需求迫切、效益明显的跨部门、跨地区信息共享。当前正在加速有关部门信息资源数字化的发展心政府等部门信息的管理，自动化网络办公的实现，重要信息的保存，信息的利用率的提高等诸多问题亟待解决。必要利用现代化的高技术手段，对这些文件进行数字化，同时提供查询功能，以方便利用，增加其价值。而目前，社会上关于文件的特定数字化系统很少，大多数宇化系统针对庞大的各种形式的信,息资源而进行设计。因此基于这样的背景，对的全文检索进行进一步的探索，以提高检索的速度、准确性和查全率。

# 2. 全文信息检索系统

## 2.1 概述

传统信息存储中记录的数据，从类型上大致可以分为三种：

- 结构化数据：指具有固定格式或有限长度的数据，如数据库，元数据等。
- 半结构化数据，如XML，HTML，JSON等文本协议。
- 非结构化数据：指不定长或无固定格式的数据，如邮件，word文档等。

现有的关系型数据库系统，都是以结构化的数据检索为主要的目标，其实现的过程相对较为简单。比如传统的数值检索，建立一个排序好的索引表，使用二分法就可以很好的实现查找，并且速度也很快。但其简单的建模能力，有限的数据类型，传统数据结构的制约等因率，都限制了其在非结构化数据中的作用。大部分的数据库引擎都采用B树来维护索引，索引的更新和维护会进行大量的I/O操作，索引的更新效率低下， 由于这些原因，在传统关系型数据库上实现全文检索，时空效率低，检索速度慢。

全文检索系统可以以各种计算机数据诸如文字，图像，声音等数据作为主要处理对象，基于文内的标引，使用自然语言进行检索的技术。与普通的数据库查询不同，全文检索不仅要查询结构化数据，还要对非结构化的数据进行高效查询 ，比起传统索引方式，全文索引提供了全新的，强大的检索方式 ，方便从多角度和和多层面的综合的提高信息的利用率 。

## 2.2 全文检索和数据库对比

对比项 | 全文检索引擎 | 数据库
-- | -- | -- 
索引 | 将数据源的所有数据都通过索引一一建立反向索引 | 对于like查询，传统索引完全不起作用，数据需要进行grep的模糊匹配 
匹配效果 | 通过词元（term）进行匹配，通过语言分析接口实现 | 使用like 会把netherlands也匹配
匹配度 | 匹配度算法，相似度高的排序在前 | 没有匹配度，匹配词出现的频率不影响排序 
结果输出 | 将最高的匹配度输出，结果集缓冲小批量读取 | 返回所有结果集，匹配条目多的时候需要非常大的内存存放临时结果集
可定制 | 通过不通的语义分析，定制需求内的索引规则 | 无法定制

由上分析比较，全文索引引擎有以下突出的优点： 
1. 索引独立应用平台，可以兼容不同应用共享索引文件
2. 在传统的索引的基础上，实现分块索引，针对新的索引建立小的索引文件，提升索引速度，并且通过合并索引进行索引优化
3. 优秀的面向对象系统架构 ，方便扩充 。
4. 设计了独立的语言和文件格式分析，扩展新的语言和文件格式只需要实现文本分析即可。
5. 默认实现强大的查询引擎 。

## 2.3 倒排索引 

倒排索引作为全文检索引擎的核心，作为底层能够建立起快速检索能力有着机器重要的作用 。


### 2.3.1 正排索引和倒排索引 
搜索的核心需求是全文检索，全文检索简单来说就是要在大量文档中找到包含某个单词出现的位置，在传统关系型数据库中，数据检索只能通过 like 来实现。


例如需要在酒店数据中查询名称包含公寓的酒店，需要通过如下 sql 实现：

```
select * from hotel_table where hotel_name like '%公寓%';
```

这种实现方式实际会存在很多问题：

无法使用数据库索引，需要全表扫描，性能差
搜索效果差，只能首尾位模糊匹配，无法实现复杂的搜索需求
无法得到文档与搜索条件的相关性
搜索的核心目标实际上是保证搜索的效果和性能，为了高效的实现全文检索，可以通过倒排索引来解决。

倒排索引是区别于正排索引的概念：

正排索引：是以文档对象的唯一 ID 作为索引，以文档内容作为记录。
倒排索引：Inverted index，指的是将文档内容中的单词作为索引，将包含该词的文档 ID 作为记录。

{% asset_img image.png 配置图 %}

有了倒排索引，能快速、灵活地实现各类搜索需求。整个搜索过程中不需要做任何文本的模糊匹配。

### 2.3.2 倒排索引的结构
根据倒排索引的概念，可以用一个 Map来简单描述这个结构。这个 Map 的 Key 的即是分词后的单词，这里的单词称为 Term，这一系列的 Term 组成了倒排索引的第一个部分 —— Term Dictionary (索引表，可简称为 Dictionary)。倒排索引的另一部分为 Postings List（记录表），也对应上述 Map 结构的 Value 部分集合。记录表由所有的 Term 对应的数据（Postings） 组成，它不仅仅为文档 id 信息，可能包含以下信息：

- 文档 id（DocId, Document Id），包含单词的所有文档唯一 id，用于去正排索引中查询原始数据。
- 词频（TF，Term Frequency），记录 Term 在每篇文档中出现的次数，用于后续相关性算分。
- 位置（Position），记录 Term 在每篇文档中的分词位置（多个），用于做词语搜索（Phrase Query）。
- 偏移（Offset），记录 Term 在每篇文档的开始和结束位置，用于高亮显示等。

## 2.4  全文检索率衡量标准

随着全文检索技术的发展，衡量全文检索系统的基本指标也逐渐形成规苑，主要指标有查全率和香准率问。
1. 查准率(Precision)
通俗点讲，就是查找的准不准。查准率是检索出的相关文档数与检索出的文档总数的比率。查准率用来衡量系统过滤掉不相关文档那个的能力。

>查准率 = 返回答案中正确的个数/返回答案的总个数

2. 查全率 (Recal)
查全率 又称召回率，是检索出的相关文档数与文档集中所有的相关文档数的比率，即得到的干确结果占所有应该得到的正确结果的比例。召回率衡量搜索系统搜索到相关文档的能力。

>查全率 = 返回答案中正确的个数/后备库中正确答案的总数 

查全率与查准率一起构成衡量检索系统优劣的重要指标，对于一个检索系统来讲，查全率和查准率是不可能同时达到最优的。查全率高时，查谁率低：查准率高时，查全率低。此外检索系统的衡量指标还包括信息检索的响应时间、信息是否完全，检索的自然程度及用户友好性等。

## 2.5 全文检索核心技术实现 

**Lucene** 

Lucene是apache下的一个子项目，是一个开放源代码的全文检索引擎工具包，但它不是一个完整的全文检索引擎，而是一个全文检索引擎的架构，提供了完整的查询引擎和索引引擎，部分文本分析引擎。

**Solr**

Solr是一个高性能，采用Java5开发，基于Lucene的全文搜索服务器。同时对其进行了扩展，提供了比Lucene更为丰富的查询语言，同时实现了可配置、可扩展并对查询性能进行了优化，并且提供了一个完善的功能管理界面，是一款非常优秀的全文搜索引擎。

**Elasticsearch**

Elasticsearch跟Solr一样，也是一个基于Lucene的搜索服务器，它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。


## 2.6. 中文分词 

中文分词是文本处理的一个基础步骤，也是中文人机自然语言交互的基础模块。不同于英文的是，中文句子中没有词的界限，因此在进行中文自然语言处理时，通常需要先进行分词，分词效果将直接影响词性、句法树等模块的效果。当然分词只是一个工具，场景不同，要求也不同。

在人机自然语言交互中，成熟的中文分词算法能够达到更好的自然语言处理效果，帮助计算机理解复杂的中文语言。竹间智能在构建中文自然语言对话系统时，结合语言学不断优化，训练出了一套具有较好分词效果的算法模型，为机器更好地理解中文自然语言奠定了基础。

### 2.6.1 中文分词处理方法 

中文分词根据实现原理和特点，主要分为以下2个类别：

1. 基于词典分词算法

也称字符串匹配分词算法。该算法是按照一定的策略将待匹配的字符串和一个已建立好的“充分大的”词典中的词进行匹配，若找到某个词条，则说明匹配成功，识别了该词。常见的基于词典的分词算法分为以下几种：正向最大匹配法、逆向最大匹配法和双向匹配分词法等。

基于词典的分词算法是应用最广泛、分词速度最快的。很长一段时间内研究者都在对基于字符串匹配方法进行优化，比如最大长度设定、字符串存储和查找方式以及对于词表的组织结构，比如采用TRIE索引树、哈希索引等。

2. 基于统计的机器学习算法

这类目前常用的是算法是HMM、CRF、SVM、深度学习等算法，比如stanford、Hanlp分词工具是基于CRF算法。以CRF为例，基本思路是对汉字进行标注训练，不仅考虑了词语出现的频率，还考虑上下文，具备较好的学习能力，因此其对歧义词和未登录词的识别都具有良好的效果。

Nianwen Xue在其论文《Combining Classifiers for Chinese Word Segmentation》中首次提出对每个字符进行标注，通过机器学习算法训练分类器进行分词，在论文《Chinese word segmentation as character tagging》中较为详细地阐述了基于字标注的分词法。

常见的分词器都是使用机器学习算法和词典相结合，一方面能够提高分词准确率，另一方面能够改善领域适应性。

3. 基于理解分词方法 

通过计算机模拟人对句子得理解，达到识别词语得小郭。通过句法，语义分析，利用句法信息和语义信息来排除歧义，这种分词需要大量得语言知识和信息，对于汉语得复杂性和笼统性，复杂性，较难组成机器可以直接读取得形式 ，目前该类型分词还处于探索阶段 。


### 2.6.2 中文分词的难题 

中文分词是个复杂的工程，即使有了相对成熱的分词处理系统，仍很雅达到理想的分词效果，这主要是因为在中文分词过程中，有两大难题一直没有完仝突破，它们是歧义消除和未登录词识别。

1. 歧义识别
分词系统要处理的第一个难题就是影响分词精度的文本中的歧义问题。歧义是指同样的一句话，可能有两种或者更多的切分方法。歧义按照结构可以分为两科类型：交集型歧义（交叉歧义）和组合型歧义（覆盖歧义）。所谓组合型歧义是指某个词的一小部分也是一个完整的词，如“中华人民共和国”，“中华”“人民”，“共和国〞 都是词，但是它们合起来也是一个词。而交集型歧义就是说两个相邻的词之间有重登的部分，如“今天下午”，“天下”是一个词，“下午”也是一个词，它们重用了一个 “下”字。研究表明，歧义的产生主要是后一种，它约占整个分词歧义的 90%。所以，处理好交集型歧义字段在很大程度上能保证一定的分词精度。显然一个好的分词器应具有对明显歧义分词的识别能力，但由于中文语言的的复杂性，要想完全避免歧义、进行完全准确的分词几乎是不可能的。因此在实际的设计中，应考虑歧义的处理，但不可求全责备。有时也可采取对歧义进行放宽处理，也即歧义包容，这样虽然对精度有些影啊，但可以明显提高的搜索速度，也会带來召回率的提升。

2. 新词识别
新词，专业术语称为未登录词。世就是那些在词典中都没有收录过，但又确实能称为词的那些词。新词主要包括：人名、地名、机构名、热点新名词等。例如：2003 年之前，没有人知道 “非典”，“非典”刚出现的时候，这就是新词。对于搜索引擎来说，分词系统中的新词识别十分重要，如何识别新词也成为分词技术研究的重点，目前新词识别准确率己经成为评价一个分词系统好坏的重要标志之一。识别新词的方法主要有两种，即基于规则的方法和基于统计、机器学习的方法


### 2.6.3 中文分词算法比较

1.基于词典分词算法

优点：简单，易于实现,便于维护定制 。
缺点：1. 匹配速度慢；2存在交集型和组合型歧义切分问题：3词本身没有一个标准的定义，没有统一标准的词集，4不同词典产生的歧义也不同；⑤缺乏自学习的智能性。

2.基于统计的机器学习算法
优点：1. 不受待处理文 本的领域限制：2. 不需要一个机器可读的词典，3. 能够有效地自动排除歧义，能够设别新词怪词。
缺点：1. 需要大量的训练文本，用以建立统计模型的参数，2. 该方法的计算量非常大：3. 对常用词的识别精度 差，且分词精度与训练文本的选择有关，4. 经常抽出一些共现频度高，但并不是词的常用字组。

3.基于理解分词方法
优点：1. 具有较高的歧义识别功能；2. 有自学习的智能性，3. 知识库易于维护和管理
缺点：1. 不销大，需要使用大量的语言知识和信息，2. 实现困难，将各种语言信息组织成机器可点接读取形式的难度较高。


# 3 全文检索服务架构说明

## 3.1 架构图 

{% asset_img image-1.png 配置图 %}

## 3.1 微服务架构 

全文检索服务采用全新微服务架构，负责服务请求路由、组合及协议转换。客户端的所有请求都首先经过API网关，然后由它将请求路由到合适的微服务。具备授权，监控，负载均衡，缓存等功能。 采用API Gateway，代理的方式，将API的管理集中化，解决了由于服务拆分带来的服务分散难于管理的问题，同时减少了微服务当中的监控，管理，认证等功能，实现统一管理管理。其核心是Nginx提供多种插件供选择。

## 3.2 微服务部署

本次系统容器化部署，一方面解决了横向扩展的数量瓶颈限制，另一方面也有效避免了随着并发数量递增系统响应速度、性能逐步降低的弊端 。

我们在实际部署中将充分利用系统中各个模块的分布式集群部署特点，原则上所有的模块均需进行集群部署以确保无单点故障 。

## 3.3 分布式实时消息 

应用基于服务架构建设，必然要以分布式方式部署，同时匹配云计算平台的逐项特性，以求更好地发挥上层应用的效能，以及在系统运维、横纵向容量扩展上取得更好的前景，但与此同时，更应关注的一点是应用层面较于传统生产运营模式而言，新衍生出的实时性的服务行为该如何于微服务云平台中获得支撑，分布式的实时消息处理技术就显得尤为重要和不可或缺，为避免消息的丢失，采用分布式消息队列的形式来构建索引一致性数据的保证 。

- 通过IO的磁盘数据结构提供消息的持久化，这种结构对于即使数以TB的消息存储也能够保持长时间的稳定性能；
- 高吞吐量，即使是非常普通的硬件Kafka也可以支持每秒数百万的消息。
- 支持通过服务器和消费机集群来分区消息；


# 4 全文检索服务关键性设计 

## 4.1 多层级的分布式设计

- 单代理多服务器设计
一个前端代理服务器可以向多个搜索核心服务器同时转发请求，并接受多个服务器的结果数据，在一个用户端界面集中呈现。

- 单服务器多索引实例设计
一个搜索核心服务器可以为不同的搜索应用配置不同的搜索上下文，提供完全独立的搜索服务。比如：多个索引目录，它们可以同处于一个实例下，根据各自的数据特点，配置独立的性能参数，实现完全独立的搜索服务。

- 索引实例多索引目录设计
当一个索引实例中的记录数过于庞大，造成搜索速度呈几何级数下降时，需要对这个索引记录进行横向拆分，这就是单索引多目录设计。比如：当数据量过于潘达，可以将其索引拆分成6个索引，在搜索的时候，需要合并留个子索引的结果，进行排序输出。

- 多实例多索引实例设计 
实现集群中多个节点，其中一个作为主节点，主节点通过集群选举产生，对外产生一个逻辑上的整体，所有节点的通信之间是等价操作，进而实现高可用，易扩展等。



## 4.2 优化的异步任务队列设计

- 高并发性与索引同步锁的冲突
构建一个支持实时搜索的索引系统，首当其冲的，就面临着多个在线业务系统并发访问的难题。使用Lucene作为底层的索引组件，其本身通过文件锁方式解决了索引同步写入带来的数据完整性问题。但是，使用文件锁实现并发访问的性能是低效的，无法支撑业务系统对索引请求的高并发需要。

- 无阻塞的请求处理
采编系统在向搜索中心请求索引处理的时候，不能因为索引系统的繁忙，而导致请求阻塞或者无响应，影响业务系统的正常运行。这要求索引系统的接口程序必须是无阻塞的

**异步任务队列来解决上述问题**

1.	HTTP请求接受索引任务，将索引指令压入队列后立刻返回，不等待索引处理完成，实现无阻塞的接口调用
2.	高性能的索引任务队列，预设5000条指令缓冲，有效因为业务系统高峰期的实时索引操作
3.	采用单线程批量任务处理模块，一次性批量读写索引文件，提高索引性能的同时，避免文件锁带来的低效率竞争
4.	同时，批量索引方式避免了索引文件过于零碎，带来磁盘读写效率的降低
5.	异步任务队列采用固定时间唤醒和任务数量满唤醒双重执行机制，有效的优化了批处理，同时兼顾了低负载情况下索引的实时性问题。


## 4.3 使用内存索引实现新数据的实时搜索

由于异步任务队列的设计，使得部分新数据在提交请求后，无法被实时查询到。为解决这个问题，引入了内存索引机制。相对于磁盘索引，内存索引有以下几点优势：

1.	没有文件同步问题，索引效率极高。
2.	不存在索引碎片，可以单条数据提交，不需要批量处理来优化。
3.	建立索引后立刻能搜索到，具有数据的事务完整性。

为此，给每个的索引实例都建立了内存索引区，数据在没有完成磁盘的持久化之前，都能在内存索引中被查询到。内存索引将作为磁盘索引的实时性补充，在用户提交搜索请求的时候，与磁盘索引一块被纳入搜索的数据范围，从而实现对新增数据的实时搜索。


## 4.4 使用单字索引和SWMC算法

为何使用单字索引，要从索引机制说起：倒排索引

{% asset_img image-2.png 配置图 %}

特点：按索引“全字”匹配，速度快；(PS:可以随索引使用部分匹配，但是性能相差甚远)
缺点：对于中文词语分词越精确，搜索效果越差。

项目遇到的实际例子：用户使用“漳州”作为关键词，查找含有“漳州市”关键字的文章。

使用单字索引：

优势在于，任何在文章中出现的“连续字串”都能匹配的到；
缺点是，搜索速度慢，对CPU和内存消耗巨大。

使用单字索引实现中文全文检索，当用户输入关键字时，采用何种匹配逻辑？？如：“漳州市人民是”

1.	采用类似“like”的全字符窜匹配？？！—— 可能无法匹配到结果 
2.	采用简单的单字AND逻辑？？！—— 可能出现五花八门答非所问的结果。
3.	采用单字切分的基础上，对语义单元进行AND逻辑查询。——理想的方案。

应运而生的SWMC算法
1.	使用中文分词，切分出“合理”的语义单元 —— 采用了排歧义的分词算法。
2.	对语义单元进行完整字符串匹配
	- 保留完整的英文和数词字串，作为一个“语义单元” 
	- 切分合理的中文词语，作为一个“语义单元”
	- 合并连续出现的未知中文单字，作为一个“语义单元”
	- 将中文“语义单位”转成“连续的单字查询”
3.	在语义单元间，采用AND逻辑 

# 5 全文检索技术优化

## 5.1 性能优化 -  filesystem cache

往全文检索中里写的数据，实际上都写到磁盘文件里去了，查询的时候，操作系统会将磁盘文件里的数据自动缓存到 filesystem cache 里面去。要让 es 性能要好，最佳的情况下，就是机器的内存，至少可以容纳总数据量的一半。

根据生产环境实践经验，最佳的情况下，是仅仅在 es 中就存少量的数据，要用来搜索的那些索引，如果内存留给 filesystem cache 的是 100G，那么就将索引数据控制在 100G 以内，这样的话，数据几乎全部走内存来搜索，性能非常之高，一般可以在 1 秒以内。

一行数据。 id,name,age .... 30 个字段。搜索需要根据 id,name,age 三个字段来搜索。如果 es 里写入一行数据所有的字段，就会导致说 90% 的数据是不用来搜索的，结果硬是占据了 es 机器上的 filesystem cache 的空间，单条数据的数据量越大，就会导致 filesystem cahce 能缓存的数据就越少。其实，仅仅写入 es 中要用来检索的少数几个字段就可以了，比如说就写入 es id,name,age 三个字段，然后可以把其他的字段数据存在 mysql/hbase 里，一般是建议用 es + hbase 这么一个架构。


## 5.2 性能优化 -  数据预热 

按照上述的方案去做了，集群中每个机器写入的数据量还是超过了 filesystem cache 一倍，比如写入一台机器 60G 数据，结果 filesystem cache 就 30G，还是有 30G 数据留在了磁盘上。

可以处理数据预热。

举个例子，拿微博来说，可以把一些大 V，平时看的人很多的数据，提前执行定时任务，每隔一会儿，自己的后台系统去搜索一下热数据，刷到 filesystem cache 里去，后面用户实际上来看这个热数据的时候，就是直接从内存里搜索了。

或者是电商，可以将平时查看最多的一些商品，比如说 iphone 8，热数据提前后台搞个程序，每隔 1 分钟自己主动访问一次，刷到 filesystem cache 里去。

对于那些觉得比较热的、经常会有人访问的数据，最好做一个专门的缓存预热子系统，就是对热数据每隔一段时间，就提前访问一下，让数据进入 filesystem cache 里面去。这样下次别人访问的时候，性能一定会好很多。

## 5.3 性能优化 -  冷热分离

类似于 mysql 的水平拆分，就是说将大量的访问很少、频率很低的数据，单独写一个索引，然后将访问很频繁的热数据单独写一个索引。最好是将冷数据写入一个索引中，然后热数据写入另外一个索引中，这样可以确保热数据在被预热之后，尽量都让他们留在 filesystem os cache 里，别让冷数据给冲刷掉。

大量的时间是在访问热数据 index，热数据可能就占总数据量的 10%，此时数据量很少，几乎全都保留在 filesystem cache 里面了，就可以确保热数据的访问性能是很高的。但是对于冷数据而言，是在别的 index 里的，跟热数据 index 不在相同的机器上，大家互相之间都没什么联系了。如果有人访问冷数据，可能大量数据是在磁盘上的，此时性能差点，就 10% 的人去访问冷数据，90% 的人在访问热数据。

## 5.4 分词器 - 性能优化

分词器是全文搜索的关键模块，它实现将输入内容拆分成多个Token并提供这些Token的位置，搜索引擎再对这些Token建立索引。本服务可以按照业务需求实现自己的分词器。

分词器的分词方法可以分为按字分词和按词分词。前者只是简单对输入内容逐字建立索引，后者则需要理解输入内容的语义，对有具体含义的词组建立索引。相比于按字分词，按词分词的优势是既可以减少建索引的Token数量，也可以减少搜索时匹配的Token数量，劣势是需要理解语义，而且用户输入的词不完整时也会有搜不到的问题。

在建立索引的时候 ，使用最大切分法进行索引建立 ，在搜索分词使用只能智能短语分词。比于简单的按字分词，这种分词方式的优势是可以将搜索时匹配的Token数量接近降低一半，提高搜索速度，而且在一定程度上可以提升搜索精度 。

## 5.5 分词器 - 分词器能力扩展 

1. 支持在分词时将繁体字转换成简体字：这样用户可以用繁体字搜到简体字内容，用简体字也能搜到繁体字内容，避免了因为汉字的简体和繁体字形相近导致用户输错的问题。

2. 支持Unicode归一化：Unicode支持相同字形的字符用不同的编码来表示，比如编码为\ue9的é和编码为\u65\u301的é有相同的字形，这会导致用户用看上去一样的内容去搜索结果搜不到的问题。Unicode归一化就是把字形相同的字符用同一个编码表示。

3. 支持过滤符号：大部分情况下，不需要支持对符号建索引，符号的重复量大而且用户一般也不会用符号去搜索内容，但是联系人搜索这个业务场景需要支持符号搜索，因为用户的昵称里面经常出现颜文字，符号的使用量不低。 

4. 支持全拼搜索和拼音首字母搜索 ，默认建立索引的的时候会进行拼音过滤器 ，分词之后再转拼音进行倒排索引建立 ，搜索的过程里也会将搜索文本进行拼音转换进行匹配度查询 。

5. 支持将字母全部转成小写：这样用户可以用小写搜到大写，反之亦然。

## 5.6 检索优化 - 多重聚合

优化查询中，包含了三种逻辑的判断，针对不同的字段进行不同的查询 ，满足相同的查询条件可以包含一个或者多个查询条件。
	- must：必须匹配，贡献算分
	- should：选择性匹配，贡献算分
	- must_not：查询字句，必须不能匹配

谨慎使用全量聚合和多重嵌套聚合，聚合的本质是不精准的，原因在于主、副本分片数据的不一致性。对于实时性业务数据，每分、每秒都有数据写入的，要考虑数据在变化，聚合结果也会随之变化。全量聚合的目的是规避聚合结果的不精准性，但是带来的则是性能问题。多重嵌套聚合随之嵌套层数的增多，复杂度也会激增，检索响应速度会变慢甚至带来性能问题。

## 5.7 检索优化 - 过滤查询

使用 filters 来优化查询，filter 查询只处理文档是否匹配与否，不涉及文档评分操作，查询的结果可以被缓存。

对于 filter 查询，提供了 filter cache 这种特殊的缓存，filter cache 用来存储 filters 得到的结果集。缓存 filters 不需要太多的内存，它只保留一种信息，即哪些文档与 filter 相匹配。同时它可以由其它的查询复用，极大地提升了查询的性能。

filter cache 会存储那些经常使用的数据，针对 filter 的缓存就是为了加速处理效率，对压缩算法要求更高。


# 6 功能点涵盖 

## 6.1 索引建立，维护 ，映射关系 

构建文档之前 存储数据之前需要先创建索引，类似于结构型数据库建库建表。创建索引时定义了每个字段的索引方式和数据类型，同时可以定义索引的一些行为配置 。 不同的索引信息对应不同的分词器以达到最佳匹配度的结果 。涵盖了索引的创建，删除，打开，关闭，重建，获取索引配置信息，创建索引映射关系 。


## 6.2 数据导入：建立文档和维护

在建立好的索引中加工预处理信息建立想对应的索引数据，数据源根据索引的映射关系来构建相对应的索引关系，涵盖了文档操作中的，添加文档，更新文档，删除文档，批量添加文档，批量删除文档，获取文档详情信息 。

不使用以上的默认方式，用户也可以自定义规则来控制动态映射，显式定义映射以指定字段的存储和索引方式。如果使用自定义的映射，则能够：

	- 区分全文字符串字段和精确值字符串字段
	- 执行特定于语言的文本分析
	- 优化字段以进行部分匹配
	- 使用自定义日期格式
	- 使用无法自动检测到的数据类型，例如geo_point和geooshape

但无法针对字段进行特定的分析器配置，有时可能会使用多个语言分析器来处理用户输入的同一字符串字段的内容则无法适应。

## 6.3  全文检索： 数据搜索和分析 

支持结构化查询（structured query）、全文查询（full text query）和结合了两者的复杂查询，搜索单个术语（terms）外，还可以执行短语搜索、相似性搜索和前缀搜索。如果需要搜索地理空间或其他数字数据，Elasticsearch支持高性能的在地理和数字查询的优化数据结构中，索引非文本的数据。

聚合功能使用了于搜索相同的优化数据结构，因此聚合的过程也非常快。 因此ES可以近乎实时的分析和可视化数据，及时的更新报告和系统监控仪表板上的数据，使得用户可以根据最新信息采取措施。

功能涵盖了 搜索建议，拼写纠错，精确搜索，范围搜索，前缀搜索，组合搜索功能 。

## 6.4 词典维护： 分词器的功能扩展 

业务使用过程中，随着业务运营，出现临时的扩展搜索需求，例如临时追加某些检索词汇，或者禁止某些搜索词，所以能够动态的加载各类名词则是全文检索日常使用中的必要条件 。 扩展词典功能涵盖：扩展词典，停止词典，同义词典 。并定时刷新词典加载到全文检索服务的核心业务 。




